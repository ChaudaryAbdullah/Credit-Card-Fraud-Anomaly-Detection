{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "270dd1bb",
   "metadata": {},
   "source": [
    "Abdullah Shakir\n",
    "\n",
    "22I-1138\n",
    "\n",
    "Messam Raza\n",
    "\n",
    "22I-1194\n",
    "\n",
    "Data Mining (CS-A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69079765",
   "metadata": {},
   "source": [
    "# *Transformer-Based Anomaly Detection Framework*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7e08c8",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook implements a state-of-the-art anomaly detection system for multivariate time series data using:\n",
    " \n",
    " 1. **Transformer Autoencoder** - For temporal feature extraction and reconstruction\n",
    " 2. **Contrastive Learning** - To distinguish normal vs. anomalous patterns\n",
    " 3. **Generative Adversarial Network (GAN)** - To handle training data contamination\n",
    " 4. **Geometric Masking** - Data augmentation for robustness\n",
    " \n",
    "## Dataset\n",
    " **Credit Card Fraud Detection Dataset**\n",
    " - Source: Kaggle/ULB Machine Learning Group\n",
    " - Features: 28 PCA-transformed features + Time + Amount\n",
    " - Task: Detect fraudulent transactions (highly imbalanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72265e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " ## üìö Section 1: Imports and Configuration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5670a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Core libraries\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, \n",
    "    precision_recall_curve, \n",
    "    auc, \n",
    "    roc_curve,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì All libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904fe6b5",
   "metadata": {},
   "source": [
    "\n",
    "## ‚öôÔ∏è Section 2: Hyperparameters and Configuration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29812853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration loaded\n",
      "‚úì Device: cpu\n",
      "‚úì Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# Data paths\n",
    "DATA_PATH = \"./data/creditcard.csv\"\n",
    "\n",
    "# Sequence generation\n",
    "WINDOW_SIZE = 10          # Sliding window size for time series\n",
    "STEP = 1                  # Step size for sliding window\n",
    "\n",
    "# Model architecture\n",
    "D_MODEL = 64              # Transformer embedding dimension\n",
    "NHEAD = 4                 # Number of attention heads\n",
    "NUM_ENCODER_LAYERS = 2    # Number of transformer encoder layers\n",
    "LATENT_DIM = 64           # Latent space dimensionality\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 5e-4      # Initial learning rate\n",
    "\n",
    "# Loss weights\n",
    "W_RECON = 1.0             # Reconstruction loss weight\n",
    "W_CONTRAST = 0.3          # Contrastive loss weight\n",
    "W_ADV = 0.01              # Adversarial loss weight\n",
    "\n",
    "# GAN training stability\n",
    "N_CRITIC = 5              # Update discriminator every N batches\n",
    "CLIP_VALUE = 0.01         # Weight clipping for WGAN\n",
    "\n",
    "# Data augmentation\n",
    "TIME_MASK_PROB = 0.1      # Probability of masking time steps\n",
    "FEATURE_MASK_PROB = 0.1   # Probability of masking features\n",
    "NOISE_STD = 0.01          # Gaussian noise standard deviation\n",
    "\n",
    "# System\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"‚úì Configuration loaded\")\n",
    "print(f\"‚úì Device: {DEVICE}\")\n",
    "print(f\"‚úì Random seed: {SEED}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d6933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
